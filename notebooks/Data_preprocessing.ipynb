{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for input and output directories\n",
    "judgement_dir = \"/home/corpadm/Downloads/legal_dataset/dataset/IN-Ext/judgement/\"\n",
    "full_summary_dir = \"/home/corpadm/Downloads/legal_dataset/dataset/IN-Ext/summary/full/\"\n",
    "segment_summary_dir = \"/home/corpadm/Downloads/legal_dataset/dataset/IN-Ext/summary/segment-wise/\"\n",
    "output_dir = \"/home/corpadm/Downloads/legal_dataset/dataset/processed-IN-Ext/\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_summaries(judgement_dir, full_summary_dir, author):\n",
    "    \"\"\"\n",
    "    Load full summaries written by a specific author.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for filename in tqdm(os.listdir(judgement_dir)):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            judgement_path = os.path.join(judgement_dir, filename)\n",
    "            summary_path = os.path.join(full_summary_dir, author, filename)\n",
    "\n",
    "            if os.path.exists(summary_path):\n",
    "                with open(judgement_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    judgement = f.read()\n",
    "                with open(summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    summary = f.read()\n",
    "                data.append({\"filename\": filename, \"judgement\": judgement, \"summary\": summary, \"author\": author})\n",
    "    return data\n",
    "def load_segment_summaries(segment_summary_dir, author):\n",
    "    \"\"\"\n",
    "    Load segment-wise summaries written by a specific author, handling potential encoding issues.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    segments = [\"analysis\", \"argument\", \"facts\", \"judgement\", \"statute\"]\n",
    "    for filename in tqdm(os.listdir(os.path.join(segment_summary_dir, author, \"analysis\"))):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            segment_text = {}\n",
    "            for segment in segments:\n",
    "                segment_path = os.path.join(segment_summary_dir, author, segment, filename)\n",
    "                if os.path.exists(segment_path):\n",
    "                    # Try reading with UTF-8, fallback to Latin-1 if decoding fails\n",
    "                    try:\n",
    "                        with open(segment_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                            segment_text[segment] = f.read()\n",
    "                    except UnicodeDecodeError:\n",
    "                        with open(segment_path, \"r\", encoding=\"latin-1\") as f:\n",
    "                            segment_text[segment] = f.read()\n",
    "            data.append({\"filename\": filename, \"segments\": segment_text, \"author\": author})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 23597.97it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 16332.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading segment-wise summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 16987.87it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 15445.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load full and segment summaries\n",
    "print(\"Loading full summaries...\")\n",
    "full_summaries_A1 = load_full_summaries(judgement_dir, full_summary_dir, \"A1\")\n",
    "full_summaries_A2 = load_full_summaries(judgement_dir, full_summary_dir, \"A2\")\n",
    "\n",
    "print(\"Loading segment-wise summaries...\")\n",
    "segment_summaries_A1 = load_segment_summaries(segment_summary_dir, \"A1\")\n",
    "segment_summaries_A2 = load_segment_summaries(segment_summary_dir, \"A2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
